# N2M Integration Checklist

## è¿è¡Œå‘½ä»¤
```bash
CUDA_VISIBLE_DEVICES=4 python scripts/run_benchmark.py \
  env.name=OpenSingleDoor \
  env.render=false \
  policy=diffusion \
  predictor=n2m \
  benchmark=evaluation \
  benchmark.num_episodes=2
```

## æµç¨‹å¯¹æ¯”ï¼šReference vs ç°åœ¨

### 1. é…ç½®åŠ è½½
**Reference (1_data_collection_with_rollout.py:354-375)**
```python
n2m_config = {
    "n2mnet": {
        "encoder": SIR_config["model"]["encoder"],
        "decoder": SIR_config["model"]["decoder"],
    },
    "preprocess": {
        "pointnum": SIR_config["dataset"]["pointnum"]
    },
    "postprocess": {
        "num_samples": 300,
        "collision_checker": {...}
    }
}
```

**ç°åœ¨ (n2m_predictor.py:231-242)**
```python
n2m_config = {
    "n2mnet": full_config["n2mnet"],
    "ckpt": str(ckpt_path),
    "preprocess": n2m_module_cfg["preprocess"],
    "postprocess": n2m_module_cfg["postprocess"]
}
```
âœ… **ä¸€è‡´**: ä¸¤è€…é…ç½®æ ¼å¼ç›¸åŒï¼Œåªæ˜¯æ•°æ®æ¥æºä¸åŒ

### 2. N2Mmodule åˆå§‹åŒ–
**Reference (1_data_collection_with_rollout.py:375-377)**
```python
SIR_predictor = N2Mmodule(n2m_config)
SIR_predictor.model.eval()
SIR_predictor.model.to(device)
```

**ç°åœ¨ (n2m_predictor.py:250-252)**
```python
self.n2m_model = N2Mmodule(n2m_config)
self.n2m_model.model.to(self.device)
self.n2m_model.model.eval()
```
âœ… **ä¸€è‡´**: å®Œå…¨ç›¸åŒçš„åˆå§‹åŒ–æµç¨‹

### 3. ç‚¹äº‘æ•è·
**Reference (train_utils.py:880-887)**
```python
pcd1 = capture_depth_camera_data(easy_env, camera_name='depth_camera1')
pcd2 = capture_depth_camera_data(easy_env, camera_name='depth_camera2')
# ... åˆå¹¶ç‚¹äº‘
all_pcd = pcd1+pcd2+pcd3+pcd4+pcd5
```

**ç°åœ¨ (n2m_predictor.py:122-135)**
```python
for cam_name in self.camera_names:
    pcd_cam = capture_depth_camera_data(unwrapped_env, camera_name=cam_name)
    point_clouds.append(pcd_cam)
pcd_merged = point_clouds[0]
for pcd_cam in point_clouds[1:]:
    pcd_merged += pcd_cam
```
âœ… **ä¸€è‡´**: ç›¸åŒçš„ç‚¹äº‘æ•è·å’Œåˆå¹¶æµç¨‹

### 4. ç‚¹äº‘æ ¼å¼è½¬æ¢
**Reference (train_utils.py:940)**
```python
pc_numpy = np.concatenate([point_cloud.points, point_cloud.colors], axis=1)
```

**ç°åœ¨ (n2m_predictor.py:138-140)**
```python
points = np.asarray(pcd_merged.points)
colors = np.asarray(pcd_merged.colors)
pcd_numpy = np.concatenate([points, colors], axis=1).astype(np.float32)
```
âœ… **ä¸€è‡´**: ç›¸åŒçš„è½¬æ¢æµç¨‹

### 5. N2M é¢„æµ‹
**Reference (train_utils.py:970, N2M README)**
```python
initial_pose, is_valid = n2m.predict(pcd_numpy)
```

**ç°åœ¨ (n2m_predictor.py:82)**
```python
predicted_pose, is_valid = self.n2m_model.predict(pcd_numpy)
```
âœ… **ä¸€è‡´**: å®Œå…¨ç›¸åŒçš„è°ƒç”¨æ–¹å¼

## é…ç½®æ–‡ä»¶ç»“æ„æ£€æŸ¥

### config.json (OpenSingleDoor_0_1_diffusion)
```json
{
    "n2mnet": {
        "encoder": {...},  âœ… æœ‰
        "decoder": {...}   âœ… æœ‰
    },
    "n2mmodule": {
        "ckpt": null,  âœ… ä¼šè¢«åŠ¨æ€è®¾ç½®
        "preprocess": {
            "pointnum": 8192  âœ… æœ‰
        },
        "postprocess": {
            "num_samples": 100,  âœ… æœ‰
            "collision_checker": {...}  âœ… æœ‰
        }
    }
}
```

### n2m.yaml
```yaml
name: n2m
type: n2m
training_folder: ${paths.predictor_data.n2m}/{task}_{layout}_{style}_{policy}/training
config_path: ${training_folder}/config.json  âœ… ä¼šè§£æä¸ºæ­£ç¡®è·¯å¾„
ckpt_path: ${training_folder}/ckpts/best_model.pth  âœ… ä¼šè§£æä¸ºæ­£ç¡®è·¯å¾„
camera_names:
  - robot0_front_depth  âœ… æ­£ç¡®çš„æ·±åº¦ç›¸æœº
```

## é¢„æœŸæ‰§è¡Œæµç¨‹

1. **å¯åŠ¨**: `python scripts/run_benchmark.py ...`
2. **ç¯å¢ƒåˆ›å»º**: åˆ›å»º OpenSingleDoor ç¯å¢ƒ (layout=0, style=1)
3. **Predictor åˆå§‹åŒ–**:
   - `N2MPredictor.__init__()` ä¿å­˜è·¯å¾„æ¨¡æ¿å’Œ camera_names
   - `N2MPredictor.load_checkpoint(task="OpenSingleDoor", policy="diffusion")`
     - ä»ç¯å¢ƒè·å–: layout=0, style=1
     - è§£æè·¯å¾„: `data/predictor/n2m/OpenSingleDoor_0_1_diffusion/training/config.json`
     - è§£æè·¯å¾„: `data/predictor/n2m/OpenSingleDoor_0_1_diffusion/training/ckpts/best_model.pth`
     - åŠ è½½ config.jsonï¼Œæå– n2mnet, preprocess, postprocess
     - åˆå§‹åŒ– N2Mmodule
4. **Episode å¾ªç¯** (2æ¬¡):
   - `env.reset()`
   - å¦‚æœå¯ç”¨ task_area_randomization:
     - æ„å»º collision checker
     - è°ƒç”¨ `predictor.predict()`:
       - æ•è·ç‚¹äº‘ (robot0_front_depth)
       - è½¬æ¢ä¸º numpy [xyz, rgb]
       - è°ƒç”¨ `n2m_model.predict(pcd_numpy)`
       - è¿”å› predicted_pose
     - ä½¿ç”¨ predicted_pose è¿›è¡Œå¯¼èˆª
   - æ‰§è¡Œæ“ä½œç­–ç•¥
   - è®°å½•ç»“æœ

## æ½œåœ¨é—®é¢˜æ£€æŸ¥

### âœ… 1. é…ç½®æ ¼å¼è½¬æ¢
- æ­£ç¡®æå– `n2mnet`, `preprocess`, `postprocess`
- æ­£ç¡®è®¾ç½® `ckpt` è·¯å¾„

### âœ… 2. N2Mmodule ä½¿ç”¨
- ä½¿ç”¨ `.model.to(device)` è€Œä¸æ˜¯ `.to(device)`
- ä½¿ç”¨ `.model.eval()` è€Œä¸æ˜¯ `.eval()`

### âœ… 3. ç‚¹äº‘æ•è·
- ä½¿ç”¨æ­£ç¡®çš„ç›¸æœºåç§° (robot0_front_depth)
- æ­£ç¡®åˆå¹¶å¤šä¸ªç‚¹äº‘ï¼ˆå¦‚æœæœ‰å¤šä¸ªç›¸æœºï¼‰

### âœ… 4. è·¯å¾„è§£æ
- ä»ç¯å¢ƒæ­£ç¡®è·å– layout å’Œ style
- ä½¿ç”¨ str.format() æ­£ç¡®æ›¿æ¢å ä½ç¬¦

## æœ€ç»ˆç¡®è®¤

- âœ… é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®
- âœ… N2Mmodule åˆå§‹åŒ–æµç¨‹ä¸ reference ä¸€è‡´
- âœ… ç‚¹äº‘æ•è·å’Œè½¬æ¢ä¸ reference ä¸€è‡´
- âœ… predict è°ƒç”¨æ–¹å¼ä¸ reference ä¸€è‡´
- âœ… è·¯å¾„è§£æé€»è¾‘æ­£ç¡®
- âœ… æ‰€æœ‰å‚æ•°ä» config.json è¯»å–ï¼Œä¸åœ¨ n2m.yaml ä¸­é‡å¤

## é¢„æœŸè¾“å‡º

```
============= N2M Predictor Path Setup =============
Task: OpenSingleDoor, Layout: 0, Style: 1, Policy: diffusion
Resolved config_path: data/predictor/n2m/OpenSingleDoor_0_1_diffusion/training/config.json
Resolved ckpt_path: data/predictor/n2m/OpenSingleDoor_0_1_diffusion/training/ckpts/best_model.pth
N2M paths verified successfully

Loading N2M model from config.json
Using checkpoint: best_model.pth
N2M config keys: ['n2mnet', 'ckpt', 'preprocess', 'postprocess']
N2M model loaded successfully

Running evaluation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:XX<00:00, XX.XXs/it]
```

ğŸ‰ **ä»£ç å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿è¡Œï¼**

